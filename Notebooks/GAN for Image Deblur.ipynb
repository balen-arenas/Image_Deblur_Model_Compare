{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Super Resolution with ESRGAN\n",
    "### Using Pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN using VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset class, transformations, and dataloader\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[index])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "    \n",
    "# define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# create dataset and dataloader\n",
    "dataset = ImageDataset(root_dir=\"/original_images\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define esrgan model architecture\n",
    "class RRDB(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.conv3(out)\n",
    "        return x + out\n",
    "# define generator and discriminator   \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_rrdb=23):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial_conv = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)  \n",
    "        self.rrdb_blocks = nn.Sequential(*[RRDB(64) for _ in range(num_rrdb)])\n",
    "        self.final_conv = nn.Conv2d(64, in_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial_feature = self.initial_conv(x)\n",
    "        out = self.rrdb_blocks(initial_feature)\n",
    "        out = self.final_conv(out)\n",
    "        return out\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Conv2d(in_feat, out_feat, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_feat))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers \n",
    "          \n",
    "        self.model = nn.Sequential(\n",
    "            *block(in_channels, 64, normalize=False),\n",
    "            *block(64, 128),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            nn.Conv2d(512, 1, 3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        return self.model(img)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContentLoss, self).__init__()\n",
    "\n",
    "    def forward(self, sr, hr):\n",
    "        return F.mse_loss(sr, hr)\n",
    "    \n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self, vgg_model):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        self.vgg = vgg_model.features[:36]\n",
    "        self.vgg.eval()\n",
    "\n",
    "    def forward(self, sr, hr):\n",
    "        sr_features = self.vgg(sr)\n",
    "        hr_features = self.vgg(hr)\n",
    "        return F.mse_loss(sr_features, hr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training loop\n",
    "def train(generator, discriminator, dataloader, num_epochs, optimizer_G, optimizer_D, criterion_content, criterion_perceptual, device):\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, img in enumerate(dataloader):\n",
    "            img = img.to(device)\n",
    "\n",
    "            # generator\n",
    "            sr_image = generator(img)\n",
    "\n",
    "            #train generator\n",
    "            optimizer_G.zero_grad()\n",
    "            content_loss = criterion_content(sr_image, img)\n",
    "            perceptual_loss = criterion_perceptual(sr_image, img)\n",
    "            g_loss = content_loss + perceptual_loss\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # train discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            real_output = discriminator(img)\n",
    "            fake_output = discriminator(sr_image.detach())\n",
    "            d_loss = F.binary_cross_entropy_with_logits(real_output, torch.ones_like(real_output)) + \\\n",
    "                     F.binary_cross_entropy_with_logits(fake_output, torch.zeros_like(fake_output))\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            if i % 40 == 0:\n",
    "                print(f\"Epoch {epoch +1}/{num_epochs}, Step {i}, G Loss: {g_loss.item()}, D Loss: {d_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# load pretrained vgg model\n",
    "vgg = models.vgg19(pretrained=True).to(device)\n",
    "criterion_content = ContentLoss()\n",
    "criterion_perceptual = PerceptualLoss(vgg)\n",
    "\n",
    "# train esrgan model\n",
    "train(generator, discriminator, dataloader, num_epochs=60, optimizer_G=optimizer_G, optimizer_D=optimizer_D, criterion_content=criterion_content, criterion_perceptual=criterion_perceptual, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save_gan_model(generator, discriminator, path):\n",
    "    torch.save({\n",
    "        'generator_state_dict': generator.state_dict(),\n",
    "        'discriminator_state_dict': discriminator.state_dict(),\n",
    "    }, path)\n",
    "\n",
    "save_gan_model(generator, discriminator, 'esrgan_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with sample image\n",
    "test_image = Image.open(\"/blurred_test_image.jpg\").convert('RGB')\n",
    "original_image = Image.open(\"/original_image.jpg\").convert('RGB')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_image = transform(test_image).unsqueeze(0).to(device)\n",
    "original_image = transform(original_image).unsqueeze(0).to(device)\n",
    "\n",
    "# generate super resolution image\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    sr_image = generator(test_image)\n",
    "\n",
    "# save and display image\n",
    "save_image(original_image, 'original_image.png')\n",
    "save_image(sr_image, 'sr_image.png')\n",
    "save_image(test_image, 'lr_image.png')\n",
    "\n",
    "# show images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(np.transpose(original_image.squeeze().cpu().numpy(), (1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Low Resolution Image')\n",
    "plt.imshow(np.transpose(test_image.squeeze().cpu().numpy(), (1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Super Resolution Image')\n",
    "plt.imshow(np.transpose(sr_image.squeeze().cpu().numpy(), (1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "sharp_image = cv2.imread('original_image.png')\n",
    "blurred_image = cv2.imread('lr_image.png')\n",
    "output_image = cv2.imread('sr_image.png')\n",
    "\n",
    "# resize images\n",
    "sharp_image = cv2.resize(sharp_image, (256, 256))\n",
    "blurred_image = cv2.resize(blurred_image, (256, 256))\n",
    "output_image = cv2.resize(output_image, (256, 256))\n",
    "\n",
    "# convert to RGB\n",
    "sharp_image = cv2.cvtColor(sharp_image, cv2.COLOR_BGR2RGB)\n",
    "blurred_image = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)\n",
    "output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# create figure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax = axes.ravel()\n",
    "\n",
    "# calculate mse and ssim and psnr\n",
    "mse_sharp = mse(sharp_image, sharp_image)\n",
    "ssim_sharp = ssim(sharp_image, sharp_image, channel_axis=-1)\n",
    "psnr_sharp = psnr(sharp_image, sharp_image)\n",
    "mse_blurred = mse(sharp_image, blurred_image)\n",
    "ssim_blurred = ssim(sharp_image, blurred_image, channel_axis=-1)\n",
    "psnr_blurred = psnr(sharp_image, blurred_image)\n",
    "mse_output = mse(sharp_image, output_image)\n",
    "ssim_output = ssim(sharp_image, output_image, channel_axis=-1)\n",
    "psnr_output = psnr(sharp_image, output_image)\n",
    "\n",
    "# plot images\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(sharp_image)\n",
    "ax[0].set_title(f\"Sharp Image\\nMSE: {mse_sharp}\\nSSIM: {ssim_sharp}\\nPSNR: {psnr_sharp}\")\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(blurred_image)\n",
    "ax[1].set_title(f\"Blurred Image\\nMSE: {mse_blurred}\\nSSIM: {ssim_blurred}\\nPSNR: {psnr_blurred}\")\n",
    "ax[2].axis('off')\n",
    "ax[2].imshow(output_image)\n",
    "ax[2].set_title(f\"Output Image\\nMSE: {mse_output}\\nSSIM: {ssim_output}\\nPSNR: {psnr_output}\")\n",
    "\n",
    "# show figure\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
