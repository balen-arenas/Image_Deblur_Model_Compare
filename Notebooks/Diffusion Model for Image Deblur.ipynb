{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet architecture\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class SharpenDataset(Dataset):\n",
    "    def __init__(self, blurred_dir, sharp_dir, transform=None):\n",
    "        self.blurred_dir = blurred_dir\n",
    "        self.sharp_dir = sharp_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = os.listdir(blurred_dir)\n",
    "        self.image_namess = os.listdir(sharp_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        blurred_path = os.path.join(self.blurred_dir, self.image_names[idx])\n",
    "        sharp_path = os.path.join(self.sharp_dir, self.image_namess[idx])\n",
    "        blurred_image = Image.open(blurred_path).convert('RGB')\n",
    "        sharp_image = Image.open(sharp_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            blurred_image = self.transform(blurred_image)\n",
    "            sharp_image = self.transform(sharp_image)\n",
    "        return blurred_image, sharp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train model\n",
    "def train_model(model, dataloader, criterion, optimizer, device, epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for blurred, sharp in dataloader:\n",
    "            blurred, sharp = blurred.to(device), sharp.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(blurred)\n",
    "            loss = criterion(output, sharp)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 60\n",
    "\n",
    "# Paths\n",
    "blurred_dir = \"/blurred_images\"\n",
    "sharp_dir = \"/original_images\"\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = SharpenDataset(blurred_dir, sharp_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model = UNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_model(model, dataloader, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"unet_model.pt\")\n",
    "print(\"Model saved to unet_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load model\n",
    "def load_model(model_path, device):\n",
    "    model = UNet()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# function to preprocess image\n",
    "def preprocess_image(image_path, transform, device):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_image = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    return input_image, image\n",
    "\n",
    "# function to sharpen image\n",
    "def sharpen_image(model, input_image):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)\n",
    "    output_image = torch.clamp(output.squeeze(0), 0, 1)  # Remove batch dimension and clip values\n",
    "    return output_image\n",
    "\n",
    "# function to postprocess image\n",
    "def postprocess_image(output_tensor):\n",
    "    output_image = transforms.ToPILImage()(output_tensor.cpu())\n",
    "    return output_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display test images\n",
    "import matplotlib.pyplot as plt\n",
    "def main():\n",
    "    model_path = \"unet_model.pt\"  # Trained model path\n",
    "    input_image_path = \"/input_blurred_image.jpg\"\n",
    "    output_image_path = \"/output_image.jpg\"\n",
    "\n",
    "    # Device configuration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Preprocessing transformation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Load the model\n",
    "    model = load_model(model_path, device)\n",
    "\n",
    "    # Preprocess the input image\n",
    "    input_image, original_image = preprocess_image(input_image_path, transform, device)\n",
    "\n",
    "    # Sharpen the image\n",
    "    output_tensor = sharpen_image(model, input_image)\n",
    "\n",
    "    # Postprocess the output image\n",
    "    output_image = postprocess_image(output_tensor)\n",
    "\n",
    "    # Save and display the result\n",
    "    output_image.save(output_image_path)\n",
    "\n",
    "    # Display original and sharpened images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Blurred Image\")\n",
    "    plt.imshow(original_image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Sharpened Image\")\n",
    "    plt.imshow(output_image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "sharp_image = cv2.imread(\"/original_image.jpg\")\n",
    "blurred_image = cv2.imread(\"/input_blurred_image.jpg\")\n",
    "output_image = cv2.imread(\"/output_image.jpg\")\n",
    "\n",
    "# resize images\n",
    "sharp_image = cv2.resize(sharp_image, (256, 256))\n",
    "blurred_image = cv2.resize(blurred_image, (256, 256))\n",
    "output_image = cv2.resize(output_image, (256, 256))\n",
    "\n",
    "# convert to RGB\n",
    "sharp_image = cv2.cvtColor(sharp_image, cv2.COLOR_BGR2RGB)\n",
    "blurred_image = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)\n",
    "output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# create figure\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax = axes.ravel()\n",
    "\n",
    "# calculate mse and ssim and psnr\n",
    "mse_sharp = mse(sharp_image, sharp_image)\n",
    "ssim_sharp = ssim(sharp_image, sharp_image, channel_axis=-1)\n",
    "psnr_sharp = psnr(sharp_image, sharp_image)\n",
    "mse_blurred = mse(sharp_image, blurred_image)\n",
    "ssim_blurred = ssim(sharp_image, blurred_image, channel_axis=-1)\n",
    "psnr_blurred = psnr(sharp_image, blurred_image)\n",
    "mse_output = mse(sharp_image, output_image)\n",
    "ssim_output = ssim(sharp_image, output_image, channel_axis=-1)\n",
    "psnr_output = psnr(sharp_image, output_image)\n",
    "\n",
    "# plot images\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(sharp_image)\n",
    "ax[0].set_title(f\"Sharp Image\\nMSE: {mse_sharp}\\nSSIM: {ssim_sharp}\\nPSNR: {psnr_sharp}\")\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(blurred_image)\n",
    "ax[1].set_title(f\"Blurred Image\\nMSE: {mse_blurred}\\nSSIM: {ssim_blurred}\\nPSNR: {psnr_blurred}\")\n",
    "ax[2].axis('off')\n",
    "ax[2].imshow(output_image)\n",
    "ax[2].set_title(f\"Output Image\\nMSE: {mse_output}\\nSSIM: {ssim_output}\\nPSNR: {psnr_output}\")\n",
    "\n",
    "# show figure\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
